<!DOCTYPE html>
<html lang="en-us^">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="gi-modules">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://gisma-courses.github.io/gi-modules///assets/images/face-sp.jpg">
    <meta property="twitter:image" content="https://gisma-courses.github.io/gi-modules///assets/images/face-sp.jpg" />
    

    
    <meta name="title" content="Change Detection - Klassifikationsverfahren" />
    <meta property="og:title" content="Change Detection - Klassifikationsverfahren" />
    <meta property="twitter:title" content="Change Detection - Klassifikationsverfahren" />
    

    
    <meta name="description" content="In den Geowissenschaften ist die Fernerkundung das einzige Messverfahren, das eine vollständige meßtechnische Abdeckung großer räumlicher Gebiete bis hin zur gesamten Erdoberfläche ermöglicht. Zur erfolgreichen Nutzung gehört sowohl die Anwendung existierender als auch die Anpassung und Entwicklung eigener Methoden.">
    <meta property="og:description" content="In den Geowissenschaften ist die Fernerkundung das einzige Messverfahren, das eine vollständige meßtechnische Abdeckung großer räumlicher Gebiete bis hin zur gesamten Erdoberfläche ermöglicht. Zur erfolgreichen Nutzung gehört sowohl die Anwendung existierender als auch die Anpassung und Entwicklung eigener Methoden." />
    <meta property="twitter:description" content="In den Geowissenschaften ist die Fernerkundung das einzige Messverfahren, das eine vollständige meßtechnische Abdeckung großer räumlicher Gebiete bis hin zur gesamten Erdoberfläche ermöglicht. Zur erfolgreichen Nutzung gehört sowohl die Anwendung existierender als auch die Anpassung und Entwicklung eigener Methoden." />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="gisma">
    <link rel="shortcut icon" href="/gi-modules/img/favicon.ico">

    <title>Change Detection - Klassifikationsverfahren | your title</title>

    <link rel="canonical" href="/gi-modules/post/2021-12-16-change-detection/">

    
    
    
    <link rel="stylesheet" href="/gi-modules/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/gi-modules/css/hugo-theme-cleanwhite.min.css">

    
    <link rel="stylesheet" href="/gi-modules/css/zanshang.css">

    
    <link href="https://cdn.jsdelivr.net/gh/FortAwesome/Font-Awesome@5.15.1/css/all.css" rel="stylesheet" type="text/css">

    
    

    
    <script src="/gi-modules/js/jquery.min.js"></script>

    
    <script src="/gi-modules/js/bootstrap.min.js"></script>

    
    <script src="/gi-modules/js/hux-blog.min.js"></script>

    
    

</head>



<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/gi-modules/"> HOME </a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                   
                    
                        
                        <li>
                            <a href="/gi-modules/categories/modules">modules</a>
                        </li>
                        
                        <li>
                            <a href="/gi-modules/categories/scidoc">scidoc</a>
                        </li>
                        
                        <li>
                            <a href="/gi-modules/categories/xtra">xtra</a>
                        </li>
                        
                    
                    
		    
                        <li><a href="/gi-modules/top/archive/">CONTENT</a></li>
                    

                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>





<script src="/gi-modules/js/toggle.js"></script>


<style type="text/css">
    header.intro-header {
        background-image: url('/gi-modules/assets/images/harz3-sp.jpg');
  max-height: 350px
    }
</style>

<header class="intro-header" >

    <div class="container">
        <div class="row">
            <div class="col-lg-0 col-lg-offset-0 col-md-0 col-md-offset-0">
                <div class="post-heading">
                   
                    <h1>Change Detection - Klassifikationsverfahren</h1>
                   
            
                            
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>





<article>
  
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                
                

<div id="TOC">

</div>

<p>In den Geowissenschaften ist die Fernerkundung das einzige Messverfahren, das eine vollständige meßtechnische Abdeckung großer räumlicher Gebiete bis hin zur gesamten Erdoberfläche ermöglicht. Zur erfolgreichen Nutzung gehört sowohl die Anwendung existierender als auch die Anpassung und Entwicklung eigener Methoden.</p>
<div id="einleitung" class="section level1">
<h1>Einleitung</h1>
<p>In der Geo- oder Umweltinformatik ist die Erfassung von Landoberflächen-Veränderungen mittels Satelliten-, Flugzeug- oder Drohnenbildern, die sogenannte Change Detection Analysis ein wichtiger Anwendungsfall. Oft werden solche Ergebnisse mit bio- und geophysikalischen oder anthropogenen Prozessen in Verbindung gebracht, um ein sowohl ein tieferes Verständnis als auch die Möglichkeit zur Entwicklung von Vorhersagemodellen zu erhalten. Um räumliche Informationen aus den zugrundeliegenden Prozessen zu erzeugen sind Bildanalysemethoden von hervorgehobener Bedeutung. Da sowohl Quantität als auch Qualität dieser <em>Bildaten</em> einen ständig wachsenden Anteil am Monitoring und der Modellierung der Umwelt übernimmt, ist es zunehmend notwendig <em>Big Data</em> Konzepte in die Analysen zu integrieren. Das heisst mit enormen Datenmengen (&gt;&gt; 10 GB) repoduzierbare Analysen vorzunehmen. Dies ist sowohl für den wissenschaftlichen Erkenntnisgewinn als auch für gesellschaftliche Zukunftsaufgaben unausweichlich.</p>
<p>Wir starten wie bereits einleitend ausgeführt mit einer skalierbaren Change Detection Analyse von Waldschäden in Mittelgebirgen, also einer typischen anwendungsorientierten Aufgabe. Skalierbar heisst dass wir die Analyse mit einem überschaubaren, den Nordwest-Harz abdeckenden Gebiet und auf zwei Zeitslots beschränken. Der resultierende Algorithmus kann jedoch auf räumlich andere oder größere Gebiete sowie zeitlich auf mehr Zeitebenen angewendet werden.</p>
<div id="informationen-aus-bilddaten" class="section level2">
<h2>Informationen aus Bilddaten</h2>
<p>Unverarbeitete Satellitenbilder sind nicht notwendigerweise auch informativ. Unser Auge kann zwar ein Echtfarbenbild relativ schlüssig und intuitiv interpretieren, aber eine zuverlässige und reproduzierbare d.h. wissenschaftlich belastbare Interpretation erfordert andere Vorgehensweisen. Ein erhblicher Vorteil von typischen Bildanalysemethoden gegenüber einer visuellen Interpretation ist es zusätzliche, gleichsam <em>unsichtbare</em> Informationen ableiten zu können. Wir haben bereits solche einfachen Indizes wie etwa den NDVI oder die Oberflächenalbedo als physikalisch begründete Umwandlung von Bildsignalen in eine Meßgröße, berechnet.</p>
<p>Um nützliche oder zielführende Informationen, z. B. über die Bodenbedeckung in einem Gebiet, zu erhalten, müssen wir die Daten daher fragestellungszentriert analysieren. Der wohl bekannteste und gängigste Ansatz ist die überwachte Klassifizierung von Bilddaten in Kategorien die von Interesse sind.</p>
<p>Diese Übung führt Sie in die Klassifizierung von Satelliten- und Luftvermessungsdaten in <code>R</code> ein.</p>
<p>Wir werden uns mit den folgenden Themen beschäftigen:</p>
<ol style="list-style-type: decimal">
<li>Vorbereiten der Arbeitsumgebung und Laden der Daten</li>
<li>Digtalisierung von Trainingsbereichen</li>
<li>Unüberwachte Klassifizierung (kmeans clustering)</li>
<li>Modelltraining</li>
<li>Überwachte Klassifizierung (random forest, Maximum Likelihood)</li>
<li>Güteschätzung Modell</li>
</ol>
</div>
</div>
<div id="klassifizierung-von-fernerkundungsdaten" class="section level1">
<h1>Klassifizierung von Fernerkundungsdaten</h1>
<p>Bitte beachten Sie, dass alle Arten der Klassifizierung eine in der Regel aufwendige Datenvorverarbeitung erfordern. Im Zentrum stehen dann Modellbildung und Qualitätsschätzung, die als handwerkliche Grundlagen der Klassifizierung betrachtet werden können, um schließlich in der Datennachverarbeitung die inhaltliche Interpretation der Ergebnisse abzuleiten. Wir werden schrittweise durch diesen Ablauf gehen.</p>
<div id="überwachte-klassifizierung" class="section level2">
<h2>Überwachte Klassifizierung</h2>
<p>Bei der überwachten Klassifizierung von Landbedeckungen wird aus einer begrenzten Menge Trainingsdaten zur Landbedeckung ein Modell abgeleitet, das die jeweilige Landbedeckung für den gesamten Datensatz vorhersagt. Die Landbedeckungstypen werden also <em>a priori</em> definiert, und das Modell versucht, diese Typen auf der Grundlage der Ähnlichkeit zwischen den Eigenschaften der Trainingsdaten und dem Rest des Datensatzes vorherzusagen.</p>
<p><img src="images/supervised_classification.jpg" /></p>
<p>Ganz pragmatisch erfordern Klassifizierungsaufgaben im Allgemeinen die folgenden Schritte:</p>
<ul>
<li>Zusammenstellung eines umfassenden Eingabedatensatzes, der eine oder mehrere Rasterebenen enthält.</li>
<li>Auswahl von Trainingsgebieten, d.h. Teilmengen von Eingabedatensätzen, für die der Fernerkundungsexperte den Landbedeckungstyp kennt. Das Wissen über die Landbedeckung kann z.B. aus eigenen oder fremden <em>in situ</em> Beobachtungen, Managementinformationen oder anderen Fernerkundungsprodukten (z.B. hochauflösenden Luftbildern) gewonnen werden.</li>
<li>Training eines Modells unter Verwendung der Trainingsflächen. Zu Validierungszwecken werden die Trainingsflächen häufig in eine oder mehrere Test- und Trainingsstichproben unterteilt, um die Leistung des Modellalgorithmus zu bewerten.</li>
<li>Anwendung des trainierten Modells auf den gesamten Datensatz, d. h. Vorhersage der Bodenbedeckungsart auf der Grundlage der Ähnlichkeit der Daten an jedem Ort mit den Klasseneigenschaften des Trainingsdatensatzes.</li>
</ul>
</div>
</div>
<div id="change-detection-waldveränderung-nord-west-harz" class="section level1">
<h1>Change Detection Waldveränderung Nord-West-Harz</h1>
<p>In diesem Tutorium werden die Sentinel-2-Bilder aus der vorherigen Übung verwendet.</p>
<div id="start---einrichten-des-der-arbeitsumgebung" class="section level2">
<h2>Start - Einrichten des der Arbeitsumgebung</h2>
<p>Sie können entweder die gespeicherten Daten aus der vorangegangenen Einheit verwenden oder einen neuen Raumausschnitt bestimmen, herunterladen und bearbeiten. Im Prinzip wird jedoch zuerst die Arbeitsumgebung geladen.</p>
<pre class="r"><code>#  ---- 0 Projekt Setup ----
# Achtung Pakete müssen evtl. manuell installiert werden
library(envimaR)

#--- Schalter für den Download der sentinel daten
get_sen = FALSE

#--- schalter ob digitalisiert werden muss falls er auf FALSE gesetzt ist werden die
# (zuvor erstellten und gesciherten Daten ) im else Teil der Verzeigung eingelesen
digitize = FALSE

## setzen des aktuellen Projektverzeichnisses (erstellt mit envimaR) als root_folder
#root_folder = find_rstudio_root_file()
root_folder = &quot;~/edu/geoinfo/&quot;
#install.packages(&quot;exactextractr&quot;)
library(exactextractr)


# Einlesen des zuvor erstellten Setup-Skripts
source(file.path(root_folder, &quot;src/functions/000_setup.R&quot;))</code></pre>
<pre><code>## Warning in fun(libname, pkgname): rgeos: versions of GEOS runtime 3.10.2-CAPI-1.16.0
## and GEOS at installation 3.8.0-CAPI-1.13.1differ</code></pre>
<pre class="r"><code>nclasses=2</code></pre>
<p>Bitte ergänzen Sie (bei auftreteneden Fehlermeldungen) etwaig fehlende oder defekte Pakete im obigen Setup-Skripts.</p>
<p>Auf der Grundlage der verfügbaren Sentinel Daten sollten nun als Erstes geeignete Datensätze für eine Oberflächenklassifikation identifiziert werden. Hierzu kann der vollständige Datensatz auch vom Kursdatenserver <a href="http://gofile.me/3Z8AJ/7Ika7zY9x">heruntergeladen</a> werden (Bitte beachten Sie dass sie im VPN bzw. UniNetz angemeldet sein müssen). Entpacken Sie diese Daten in das Wurzelverzeichnis des Kursprojekts. Das heisst der dort bereits vorhandene Ordner <code>data</code> wird ersetzt/ergänzt.</p>
</div>
<div id="schritt-1-übersicht-verschaffen" class="section level2">
<h2>Schritt 1 Übersicht verschaffen</h2>
<p>Bei näherer Betrachtung der RGB Bilder (RGB432B) zeigt sich, das vier Datensätze aufgrund der Bildqualität und geringen Wolkenbedeckung geeignet zu sein scheinen. Es handelt sich um den 19.06. bzw. 24.7. 2019 und den 33.06 bzw. 30.7. 2020. Aufgrund des früheren Vegetationszeitpunktes wurden die Maibilder gewählt, da hier evtl. Aufwuchs auf den Rodungsflächen weniger stark sichtbar sein könnte.</p>
<p>Zunächst müssen diese Daten in einem <em>“Rasterstapel”</em> also einem Mehrkanalbild verfügbar sein. Bereits bei der ersten Beschäftigung mit dem <code>sen2r</code> Paket hatten wir weitere Produkte als sinnvoll erachtet und berechnet. Es sind folgende Indizes:</p>
<ul>
<li>Normalized Difference Vegetation Index <a href="https://www.indexdatabase.de/db/i-single.php?id=58">NDVI</a></li>
<li>Modified Soil Adjusted Vegetation Index <a href="https://www.indexdatabase.de/db/i-single.php?id=44">MSAVI2</a></li>
<li>Simple Ratio 1600/820 Moisture Stress Index <a href="https://www.indexdatabase.de/db/i-single.php?id=48">MSI</a></li>
<li>Modified Soil Adjusted Vegetation Index <a href="https://www.indexdatabase.de/db/i-single.php?id=87">SAVI</a></li>
<li>Enhanced Vegetation Index <a href="https://www.indexdatabase.de/db/i-single.php?id=16">EVI</a></li>
</ul>
<div id="download-mit-sen2r" class="section level3">
<h3>Download mit sen2r</h3>
<p>Diese Daten müssen für den gewünschten Zeitslot und Raumausschnitt besorgt und vorbereitet werden. Aus Gründen der Vereinfachung gibt es für den Kurs eine entsprechende sen2R-Projektdatei:</p>
<p>
<button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#collapse_json" aria-expanded="false" aria-controls="collapse_json">
Verwendete sen2R Projektdatei
</button>
<div id="collapse_json" class="collapse">
<div class="card card-body">
<pre class="r"><code>{
  &quot;preprocess&quot;: [true],
  &quot;s2_levels&quot;: [&quot;l1c&quot;, &quot;l2a&quot;],
  &quot;sel_sensor&quot;: [&quot;s2a&quot;, &quot;s2b&quot;],
  &quot;online&quot;: [true],
  &quot;server&quot;: [&quot;scihub&quot;],
  &quot;order_lta&quot;: [true],
  &quot;downloader&quot;: [&quot;builtin&quot;],
  &quot;overwrite_safe&quot;: [false],
  &quot;rm_safe&quot;: [&quot;l1c&quot;],
  &quot;max_cloud_safe&quot;: [5],
  &quot;step_atmcorr&quot;: [&quot;auto&quot;],
  &quot;sen2cor_use_dem&quot;: [true],
  &quot;sen2cor_gipp&quot;: [null],
  &quot;timewindow&quot;: [&quot;2019-06-01&quot;, &quot;2020-08-31&quot;],
  &quot;timeperiod&quot;: [&quot;seasonal&quot;],
  &quot;extent&quot;: [&quot;{\n  \&quot;type\&quot;: \&quot;FeatureCollection\&quot;,\n  \&quot;features\&quot;: [\n    {\n      \&quot;type\&quot;: \&quot;Feature\&quot;,\n      \&quot;properties\&quot;: {\n        \&quot;X_leaflet_id\&quot;: 2080,\n        \&quot;layerId\&quot;: \&quot;2080\&quot;,\n        \&quot;edit_id\&quot;: \&quot;2080\&quot;\n      },\n      \&quot;geometry\&quot;: {\n        \&quot;type\&quot;: \&quot;Polygon\&quot;,\n        \&quot;coordinates\&quot;: [\n          [\n            [10.198975, 51.848575],\n            [10.198975, 51.947721],\n            [10.413895, 51.947721],\n            [10.413895, 51.848575],\n            [10.198975, 51.848575]\n          ]\n        ]\n      }\n    }\n  ]\n}&quot;],
  &quot;s2tiles_selected&quot;: [&quot;32UNC&quot;],
  &quot;s2orbits_selected&quot;: [null],
  &quot;list_prods&quot;: [&quot;BOA&quot;, &quot;SCL&quot;, &quot;CLD&quot;],
  &quot;list_indices&quot;: [&quot;EVI&quot;, &quot;MSAVI2&quot;, &quot;MSI&quot;, &quot;NDVI&quot;, &quot;NDWI2&quot;, &quot;SAVI&quot;],
  &quot;list_rgb&quot;: [&quot;RGB432B&quot;, &quot;RGB843B&quot;],
  &quot;rgb_ranges&quot;: [
    [null],
    [
      [0, 7500],
      [0, 2500],
      [0, 2500]
    ]
  ],
  &quot;index_source&quot;: [&quot;BOA&quot;],
  &quot;mask_type&quot;: [&quot;nodata&quot;],
  &quot;max_mask&quot;: [5],
  &quot;mask_smooth&quot;: [20],
  &quot;mask_buffer&quot;: [10],
  &quot;clip_on_extent&quot;: [true],
  &quot;extent_as_mask&quot;: [true],
  &quot;extent_name&quot;: [&quot;harz&quot;],
  &quot;reference_path&quot;: [null],
  &quot;res&quot;: [null],
  &quot;res_s2&quot;: [&quot;10m&quot;],
  &quot;unit&quot;: [&quot;Meter&quot;],
  &quot;proj&quot;: [null],
  &quot;resampling&quot;: [&quot;near&quot;],
  &quot;resampling_scl&quot;: [&quot;near&quot;],
  &quot;outformat&quot;: [&quot;GTiff&quot;],
  &quot;rgb_outformat&quot;: [&quot;GTiff&quot;],
  &quot;index_datatype&quot;: [&quot;Int16&quot;],
  &quot;compression&quot;: [&quot;DEFLATE&quot;],
  &quot;rgb_compression&quot;: [&quot;DEFLATE&quot;],
  &quot;overwrite&quot;: [false],
  &quot;path_l1c&quot;: [&quot;~/edu/geoinfo/data/data_lev0&quot;],
  &quot;path_l2a&quot;: [&quot;~/edu/geoinfo/data/data_lev0&quot;],
  &quot;path_tiles&quot;: [null],
  &quot;path_merged&quot;: [null],
  &quot;path_out&quot;: [&quot;~/edu/geoinfo/data/data_lev1&quot;],
  &quot;path_rgb&quot;: [&quot;~/edu/geoinfo/data/data_lev1&quot;],
  &quot;path_indices&quot;: [&quot;~/edu/geoinfo/data/data_lev1&quot;],
  &quot;path_subdirs&quot;: [true],
  &quot;thumbnails&quot;: [true],
  &quot;log&quot;: [&quot;~/edu/geoinfo//doc/nw-harz.log&quot;],
  &quot;parallel&quot;: [true],
  &quot;processing_order&quot;: [&quot;by_date&quot;],
  &quot;pkg_version&quot;: [&quot;1.5.0.9000&quot;]
}

}
</code></pre>
</div>
</div>
<p>Bitte unbedingt beachten das die Daten die älter als 18 Monate sind im Long Term Archive liegen.</p>
<pre class="r"><code>#--- Download der Daten
# gui = TRUE ruft die GUI zur Kontrolle auf

if (get_sen){
   out_paths_3 &lt;- sen2r(
    gui = T,
    param_list = &quot;~/edu/geoinfo/data/harz_2022.json&quot;,
    tmpdir = envrmt$path_tmp,
  )
}</code></pre>
<p>In diesem Beispiel löst der obige Befehl eine <em>Bestellung</em> aus. <code>sen2r</code> gibt dann dazu eine Meldung aus die unbedingt gespeichert und dann für den weiteren Download berücksichtigt werden muss. Die Ausgabe schaut vergleichbar wie nachfolgend aus.</p>
<pre><code># ╔══════════════════════════════════════════════════════════════════════════════════════════════════════════
# ║ sen2r Processing Report
# ╟──────────────────────────────────────────────────────────────────────────────────────────────────────────
# ║ Dates to be processed based on processing parameters: 9
# ║ Processing completed for: 0 out of 9 expected dates.
# ║ Outputs for: 9 out of 9 expected dates not created because all/some required images are currently
# ║ offline.
# ║ Order for: 9 out of 9 offline images successfull.
# ║ You can check later if the ordered images are online with the command:
# ║   safe_is_online(&quot;/home/creu/.sen2r/lta_orders/lta_20220220_134628.json&quot;)
# ║ When additional images are online, you can relaunch the processing chain using the command:
# ║   sen2r(&quot;/home/creu/.sen2r/proc_par/s2proc_20220220_134550.json&quot;)
# ╚══════════════════════════════════════════════════════════════════════════════════════════════════════════</code></pre>
<p>Wichtig sind die beiden Befehle mit den <em>“Vorgangsnummern”</em>:
Mit dem ersten Befehl kann gecheckt werden ob die Daten bereits im Zugriff sind. Dies dauert in der Regel nicht länger als 30 Minuten. Mit dem zweiten Befehl können die bestellten Daten heruntergeladen und prozessiert werden. Bitte beachten Sie, dass eine gute Internetverbindung besteht.</p>
<pre><code>safe_is_online(&quot;/home/creu/.sen2r/lta_orders/lta_20220220_134628.json&quot;)
sen2r(&quot;/home/creu/.sen2r/proc_par/s2proc_20220220_134550.json&quot;)</code></pre>
</div>
<div id="vorbereitung-der-daten" class="section level3">
<h3>Vorbereitung der Daten</h3>
<p>Sobald der Download erfolgreich war kann mit der eigenlichen Klassifikation begonnen werden. Zuerst müssen die Daten in technisch geeigneter Weise als Multikanalbild organisiert werden. Zusätzlich wird ein aktueller bzw. zeitlich korrespondierender Corine Landnutzungsdatensatz geladen, um eine binäre Wald/nicht Wald Maske zu erzeugen. Für den <a href="https://land.copernicus.eu/pan-european/corine-land-cover">Download der Corine Daten</a> kann das bereits verfügbare Copernicus Konto genutzt werden. Nach dem (manuellen) Download die Daten in das Unterverzeichnis <code>level0</code> entpacken (Achtung hier gibt es nach dem Entpacken des Archivs zahllose Unterverzeichnisse). Wir benötigen die Datei <code>U2018_CLC2018_V2020_20u1.tif</code>. Alternativ kann der bereits korrekt prozesierte und projizierte Datensatz vom github repository (siehe Skript) genutzt werden.</p>
<pre class="r"><code>#--- Einlesen der Daten aus den Verzeichnissen

##--- Hier wird die Bearbeitung des corine Landnutzungsdatensatz beschrieben
## Die notwendige Datei kann auch aus dem repository heruntergeladen werden
## Für den Download ist ein Konto notwendig https://land.copernicus.eu/pan-european/corine-land-cover
## Daher die Daten manuell herunterladen und in das Verzeichnis kopieren und entpacken
## Dann das nachfolgend auskommentierte Snippet ausführen

# corine_eu = raster(file.path(envrmt$path_data_lev0,&quot;u2018_clc2018_v2020_20u1_raster100m/DATA/U2018_CLC2018_V2020_20u1.tif&quot;))
# tmp = projectRaster(pred_stack_2019[[1]],crs = crs(corine_eu))
# corine_crop = raster::crop(corine_eu,tmp)
# corine_utm = projectRaster(corine_crop,crs = crs(pred_stack_2019))
# corine = resample(corine_utm,pred_stack_2019[[1]])
# raster::writeRaster(corine,file.path(envrmt$path_data_lev0,&quot;/corine.tif&quot;),overwrite=TRUE)

# Alternativ den Beipieldatensatz herunterladen
utils::download.file(url=&quot;https://github.com/gisma/gismaData/raw/master/geoinfo/corine.tif&quot;,destfile=file.path(envrmt$path_data_lev0,&quot;corine.tif&quot;))
corine = raster(&quot;/home/creu/edu/geoinfo/data/data_lev0/corine.tif&quot;)

# Erstellen einer Wald-Maske
# Agro-forestry areas code=22, Broad-leaved forest code=23,
# Coniferous forest code=24, Mixed forest code=25
mask = reclassify(corine,c(-100,22,0,22,26,1,26,500,0))
plot(mask)</code></pre>
<p><img src="https://gisma-courses.github.io/gi-modules/post/2021-12-16-change-detection/index_files/figure-html/stack-1.png" width="672" /></p>
<pre class="r"><code># RGB stack der beiden Jahre
pred_stack_2019 = raster::stack(list.files(file.path(envrmt$path_data_lev1,&quot;BOA&quot;),pattern = &quot;20190619&quot;,full.names = TRUE))
pred_stack_2020 = raster::stack(list.files(file.path(envrmt$path_data_lev1,&quot;BOA&quot;),pattern = &quot;20200623&quot;,full.names = TRUE))


# Stack-Loop über die Daten
for (pat in c(&quot;EVI&quot;,&quot;MSAVI2&quot;,&quot;NDVI&quot;,&quot;SAVI&quot;)){
  pred_stack_2019 = raster::stack(pred_stack_2019,stack(list.files(file.path(envrmt$path_data_lev1,pat),pattern = &quot;20190619&quot;,full.names = TRUE)))
  pred_stack_2020 = raster::stack(pred_stack_2020,stack(list.files(file.path(envrmt$path_data_lev1,pat),pattern = &quot;20200623&quot;,full.names = TRUE)))
}
# get rid of NA
pred_stack_2019 = reclassify(pred_stack_2019, cbind(NA, 0))
pred_stack_2020 = reclassify(pred_stack_2020, cbind(NA, 0))

# Zuweisen von leserlichen Namen auf die Datenebenen
names(pred_stack_2019) = c(&quot;band1&quot;,&quot;band2&quot;,&quot;band3&quot;,&quot;band4&quot;,&quot;band5&quot;,&quot;band6&quot;,&quot;band7&quot;,&quot;band8&quot;,&quot;band9&quot;,&quot;band10&quot;,&quot;band11&quot;,&quot;EVI&quot;,&quot;MSAVI2&quot;,&quot;NDVI&quot;,&quot;SAVI&quot;)
names(pred_stack_2020) =  c(&quot;band1&quot;,&quot;band2&quot;,&quot;band3&quot;,&quot;band4&quot;,&quot;band5&quot;,&quot;band6&quot;,&quot;band7&quot;,&quot;band8&quot;,&quot;band9&quot;,&quot;band10&quot;,&quot;band11&quot;,&quot;EVI&quot;,&quot;MSAVI2&quot;,&quot;NDVI&quot;,&quot;SAVI&quot;)
saveRDS(pred_stack_2019,paste0(envrmt$path_data,&quot;pred_stack_2019.rds&quot;))
saveRDS(pred_stack_2020,paste0(envrmt$path_data,&quot;pred_stack_2020.rds&quot;))
pred_stack_2019 = readRDS(paste0(envrmt$path_data,&quot;pred_stack_2019.rds&quot;))
pred_stack_2020 = readRDS(paste0(envrmt$path_data,&quot;pred_stack_2020.rds&quot;))


# visuelle Überprüfung der stacks
plot(pred_stack_2019)</code></pre>
<p><img src="https://gisma-courses.github.io/gi-modules/post/2021-12-16-change-detection/index_files/figure-html/stack-2.png" width="672" /></p>
<pre class="r"><code>plot(pred_stack_2020)</code></pre>
<p><img src="https://gisma-courses.github.io/gi-modules/post/2021-12-16-change-detection/index_files/figure-html/stack-3.png" width="672" /></p>
</div>
<div id="erster-eindruck---k-means-cluster-klassifikation" class="section level3">
<h3>Erster Eindruck - K-Means Cluster-Klassifikation</h3>
<p>Die wohl bekannteste unüberwachte Klassifizierungstechnik ist das K-means-Clustering, das auch als der <em>“einfachster Algorithmus des maschinellen Lernens”</em> bezeichnet wird. Er wird häufig angewendet um einen ersten Überblick zu erhaltne ob die Rasterdaten im Merkmalsraum ausreichend trennbar sind.</p>
<p>In unserem Beispiel (auf 5 Klassen angewendet und mit <code>unsuperClass</code> Funktion aus dem <code>RStoolbox</code> Paket ausgeführt) sieht das wie folgt aus. Der Clusteralgorithmus kann mit 5 Clustern eine recht passable Trennung der Lichtungen/Kahlschläge hinbekommen was eine Klassifikation vielversprechend erscheinen läßt. Experimetiren sie auch mit anderen Clustereinstellungen und diskutieren sie die Ergebnisse.</p>
<pre class="r"><code>## k-means über RStoolbox
# Modell
prediction_kmeans_2019 = RStoolbox::unsuperClass(pred_stack_2019, nClasses = 5,norm = TRUE, algorithm = &quot;MacQueen&quot;)
# Klassifikation
plot(prediction_kmeans_2019$map)

prediction_kmeans_2020 = RStoolbox::unsuperClass(pred_stack_2020, nClasses = 5,norm = TRUE, algorithm = &quot;MacQueen&quot;)
plot(prediction_kmeans_2020$map)</code></pre>
<p><img src="images/kmeans-2020.png" />
<img src="images/kmeans-2019.png" /></p>
</div>
</div>
<div id="schritt-2---trainingsdaten-erstellen" class="section level2">
<h2>Schritt 2 - Trainingsdaten erstellen</h2>
<p>Für eine überwachte Klassifikation benötigen wir Daten die ausweisen zu welcher Oberflächenklasse definierte Flächen des Satellitenbildes gehören. diese Daten werden Trainingsdaten genannt und sehr häufig durch manuelles abdigitalisieren erfasst. Dies kann recht komfortabel in RStudio durchgeführt werden, falls nur schnell und effektiv einige wenige Trainingsflächen zu digitalisieren sind.</p>
<p>Für größere Aufgaben ist es sinnvoll, auf den hohen Komfort z.b. der <a href="https://docs.qgis.org/3.16/en/docs/training_manual/create_vector_data/create_new_vector.html#basic-ty-digitizing-polygons">Digitalisierung Turorial</a> in the QGIS 3.16 documentation zurückgreifen.</p>
</div>
<div id="trainingsdaten-digitalisieren" class="section level2">
<h2>Trainingsdaten digitalisieren</h2>
<p>Wir nehmen an, dass wir zwei Arten von Landbedeckung klassifizieren wollen: <em>clearcut</em> (Abholzungen) und <em>other</em> (Anderes). Mit mapedit `muss jede Klasse <strong>einzeln</strong> digitalisiert werden. Sobald die Trainingsgebiete als Vektordaten verfügbar sind können die Merkmale des jeweiligen Rasterstacks entsprechend der digitalisierten Klassen in eine Tabelle extrahiert und auf etwaige Fehlwerte bereiningt werden.</p>
<div class="boxSuccess">
<p class="textline">
Falls dieser Teil bereits absolviert wurde kann die logische Variable (am Anfang des Scripts definiert) <em>digitize</em> auf <em>FALSE</em> gesetzt werden und es wird dann der <em>else</em> Teil der Verzweigung durchlaufen - also nur noch die existierenden Daten eingelesen.
</div>
<p>
<button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#collapse_2" aria-expanded="false" aria-controls="collapse_2">
</p>
Exkurs: Trainingsgebiete mit mapedit erfassen
</button>
<div id="collapse_2" class="collapse">
<div id="verwendung-von-farbkomposita-für-bessere-trainingsergebnisse" class="section level3 card card-body">
<h3>Verwendung von Farbkomposita für bessere Trainingsergebnisse</h3>
<p>Für diese Übung verwenden wir <code>mapedit</code>, ein kleines, aber feines Paket, das die Digitalisieren und Editieren von Vektordaten im Rstudio- oder externen -browser ermöglicht. In Kombination mit <code>mapview</code> können auch beliebige <a href="https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/composites/">Farbkomposita</a> als Grundlage für die Digitalisierung verwendet werden.</p>
<pre class="r"><code>
m1 = tm_shape(pred_stack_2019) + tm_rgb(r=4, g=3, b=2) +
  tm_layout(legend.outside.position = &quot;right&quot;,
            legend.outside = T,
            panel.label.height=0.6,
            panel.label.size=0.6,
            panel.labels = c(&quot;r=1, g=2, b=3&quot;)) +
  tm_grid()

m2 = tm_shape(pred_stack_2019) + tm_rgb(r=8, g=4, b=3) +
  tm_layout(legend.outside.position = &quot;right&quot;,
            legend.outside = T,
            panel.label.height=0.6,
            panel.label.size=0.6,
            panel.labels = c(&quot;r=8, g=4, b=3&quot;)) +
  tm_grid()
tmap::tmap_arrange(m1,m2)
  </code></pre>
<p><img src="images/rgb.png" /></p>
<p>Verwenden Sie die Ebenensteuerung, um die Ebenen umzuschalten.
Bei Echtfarbkompositen werden die sichtbaren Spektralkanäle Rot (B04), Grün (B03) und Blau (B02) den entsprechenden roten, grünen bzw. blauen Farbkanälen zugeordnet, wodurch ein quasi natürliches <em>“farbiges”</em> Bild der Oberfläche entsteht, wie es ein Mensch sehen würde, der auf dem Satelliten sitzt.
Falschfarbenbilder werden häufig mit den Spektralkanälen für das nahe Infrarot, Rot und Grün erzeugt. Sie eignen sich hervorragend für die Einschätzung der Vegetation, da Pflanzen nahes Infrarot und grünes Licht reflektieren, während sie rotes Licht absorbieren (Red Edge Effect). Ein dichterer Pflanzenbewuchs ist dunkler rot. Städte und offener Boden sind grau oder hellbraun, und Wasser erscheint blau oder schwarz.</p>
<pre class="r"><code>#---- Digitalisierung der Trainingsdaten ----

if (digitize) {
  # Für die überwachte Klassifikation benötigen wir Trainingsgebiete. Sie können Sie wie nachfolgend digitalisieren oder alternativ z.B. QGis verwenden
  
  # clearcut
  
  # Für das Falschfarbenkomosit r = 8, g = 4, b = 3, maxpixels =  1693870)
  # maxpixels hat deutlich höheren speicherbedarf, Vegetation in Rot
  # nachfolgend das Echtfarbkomposit
  train_area_2019 &lt;- mapview::viewRGB(pred_stack_2019, r = 4, g = 3, b = 2, maxpixels =  1693870) %&gt;% mapedit::editMap()
  # Hinzufügen der Attribute class (text) und id/year (integer)
  clearcut_2019 &lt;- train_area_2019$finished$geometry %&gt;% st_sf() %&gt;% mutate(class = &quot;clearcut&quot;, id = 1,year=2019)
  train_area_2020 &lt;- mapview::viewRGB(pred_stack_2020, r = 4, g = 3, b = 2,maxpixels =  1693870) %&gt;% mapedit::editMap()
  clearcut_2020 &lt;- train_area_2020$finished$geometry %&gt;% st_sf() %&gt;% mutate(class = &quot;clearcut&quot;, id = 1,year=2020)
  
  # other: alle nicht zu Kahlschlag  gehörenden Flächen möglichst repräsentativ
  train_area_2019 &lt;- mapview::viewRGB(pred_stack_2019, r = 4, g = 3, b = 2) %&gt;% mapedit::editMap()
  other_2019 &lt;- train_area_2019$finished$geometry %&gt;% st_sf() %&gt;% mutate(class = &quot;other&quot;, id = 2,year=2019)
  train_area_2020 &lt;- mapview::viewRGB(pred_stack_2020, r = 4, g = 3, b = 2) %&gt;% mapedit::editMap()
  other_2020 &lt;- train_area_2020$finished$geometry %&gt;% st_sf() %&gt;% mutate(class = &quot;other&quot;, id = 2,year=2020)
  
  train_areas_2019_2020 &lt;- rbind(clearcut_2019,clearcut_2020, other_2019,other_2020)  # Umprojizieren auf die Raster Datei
  train_areas_2019 = sf::st_transform(train_areas_2019_2020,crs = sf::st_crs(pred_stack_2019))
  mapview(filter(train_areas_2019_2020,year==2019), zcol=&quot;class&quot;)
  # sichern der geometrien
  st_write(train_areas_2019_2020,paste0(envrmt$path_data,&quot;train_areas_2019_2020.gpkg&quot;))
  
  # Extraktion der Trainingsdaten für die digitalisierten Flächen
  tDF_2019 = exactextractr::exact_extract(pred_stack_2019, filter(train_areas_2019_2020,year==2019),  force_df = TRUE,
                                          include_cell = TRUE,include_xy = TRUE,full_colnames = TRUE,include_cols = &quot;class&quot;)
  tDF_2020 = exactextractr::exact_extract(pred_stack_2020, filter(train_areas_2019_2020,year==2020),  force_df = TRUE,
                                          include_cell = TRUE,include_xy = TRUE,full_colnames = TRUE,include_cols = &quot;class&quot;)
  
  #  auch hier wieder zusamenkopieren in eine Datei
  tDF_2019 = dplyr::bind_rows(tDF_2019)
  tDF_2019$year = 2019
  tDF_2020 = dplyr::bind_rows(tDF_2020)
  tDF_2020$year = 2020
  # Löschen von etwaigen Zeilen die NA (no data) Werte enthalten
  tDF_2019 = tDF_2019[complete.cases(tDF_2019) ,]
  tDF_2020 = tDF_2020[complete.cases(tDF_2020) ,]
  
  tDF= rbind(tDF_2019,tDF_2020)
  
  # check der extrahierten Daten
  summary(tDF)
  
  # Abspeichern als R-internes Datenformat
  # ist im Repo hinterlegt und kann desahlb (zeile drunter) eingeladen werden
  saveRDS(tDF, paste0(envrmt$path_data,&quot;tDF.rds&quot;))

  
  
} else {
  tDF = readRDS(paste0(envrmt$path_data,&quot;tDF.rds&quot;))
}</code></pre>
<p>Als Resultat liegt nun eine Tabele mit den Trainingsdaten für 2019 und 2020 vor. Der Datensatz beinhalten alle Rasterinformationen über alle Bänder die von den Polygonen für die Klassen <em>“clearcut”</em> und <em>“other”</em> abgedeckt werden.</p>
<pre class="r"><code>head(tDF)</code></pre>
<pre><code>##      class band1 band2 band3 band4 band5 band6 band7 band8 band9 band10 band11
## 1 clearcut   217   342   491   600  1172  1640  1934  1977  1970   2148   1397
## 2 clearcut   217   458   600   818  1172  1640  1934  1905  1970   2148   1397
## 3 clearcut   217   408   592   804   881  1608  1880  2006  1970   1719   1017
## 4 clearcut   217   476   645   973  1172  1640  1934  2033  1970   2148   1397
## 5 clearcut   217   515   688  1070  1172  1640  1934  2032  1970   2148   1397
## 6 clearcut   217   515   726  1106  1163  1670  1883  2144  1970   2154   1376
##    EVI MSAVI2 NDVI SAVI      x       y   cell coverage_fraction year
## 1 2646   2379 5343 2726 586825 5752515 547578         0.1808126 2019
## 2 2031   1812 3992 2111 586835 5752515 547579         0.2289179 2019
## 3 2182   2002 4278 2309 586815 5752505 549076         0.1258057 2019
## 4 1853   1717 3526 1986 586825 5752505 549077         0.8988571 2019
## 5 1648   1536 3101 1781 586835 5752505 549078         0.9373500 2019
## 6 1740   1642 3194 1887 586845 5752505 549079         0.1890163 2019</code></pre>
</div>
</div>
</div>
<div id="schritt-3---modelltraining-prüfen-der-modellgüte-klassifikation" class="section level2">
<h2>Schritt 3 - Modelltraining, Prüfen der Modellgüte, Klassifikation</h2>
<p>Klassifikatoren (z.B der Maximum-Likelihood Klassikator) oder Algorithmen des maschinellen Lernens (wie z. B. Random Forest) ermitteln auf Basis der Trainingsdaten Beschreibungsmodelle die z.B. statistische Signaturen, Klassifikationsbäume oder andere Funktionen darstellen. Im Rahmen der Güte der Trainingsdaten sind solche Modelle geeignet und repräsentativ um Vorhersagen für Räume zu treffen falls die Prädiktoren aus dem Modell flächendeckend vorhanden sind.</p>
<p>Wir wollen nun die räumlichen Merkmale Kahlschlag/kein Wald exemplarisch mit einer Maximum Likelihood Klassifikation und mit Random Forest vorhersagen und Standardmethoden der Zufallsvalidierung und Modellgüteeinschätzung anwenden.</p>
<p>Ziel ist es Kahlschläge von allen anderen Pixeln zu trennen und die Unterschide von 2019/2020 zu quantifizieren.</p>
<div id="maximum-likelihood-klassifikation" class="section level3">
<h3>Maximum Likelihood Klassifikation</h3>
<p>Bei der Maximum-Likelihood-Klassifizierung wird davon ausgegangen, dass die Verteilung der Daten für jede Klasse und in jedem Kanal normal verteilt sind. Unter dieser Vorraussetzung wird die Wahrscheinlichkeit berechnet, dass ein bestimmtes Pixel zu einer bestimmten Klasse gehört. Da auch die Wahrscheinlichkeiten als Schwellenwert angegeben werden können werden ohne diese Einschränkung <em>alle</em> Pixel ungeachtet wie unwahrscheinlich zugeordnet. Jedes Pixel wird der Klasse zugeordnet, die die höchste Wahrscheinlichkeit aufweist (d. h. die maximale Wahrscheinlichkeit).</p>
<p><img src="images/max.png" /></p>
<p>Da der Maximum-Likelihood-Algorithmus Trainingsdaten benötigt, handelt es sich um eine überwachte Lernmethode. Das bedeutet, dass wir als Nutzer dem Algorithmus Daten zur Verfügung stellen müssen, die im Wissen über die vorherzusagenden Klassen vermitteln. Diese Daten werden dann in Trainings- und Testdaten aufgeteilt.</p>
<pre class="r"><code># ---- Maximum Likelihood Classification ----

tDF = readRDS(paste0(envrmt$path_data,&quot;tDF.rds&quot;))
  
## Hier wird der Random Forest über das Utility Paket caret aufgerufen
# Setzen eines &quot;seed&quot; ermöglicht reproduzierbaren Zufall
set.seed(123)

# Zufälliges Ziehen von 15% der Daten (Training/Test)
idx = createDataPartition(tDF$class,list = FALSE,p = 0.05)
trainDat = tDF[idx,]
testDat = tDF[-idx,]

#  Response-Variable (=Spalte &quot;class&quot;) muss den Datentyp &quot;factor&quot; haben
trainDat$class &lt;- as.factor(trainDat$class)
testDat$class &lt;- as.factor(testDat$class)


# superClass() Funktion aus dem Paket RSToolbox erfordet die Konvertierung der Tabelle in das
# geforderte (alte) SpatialdataPointObjekt

sp_trainDat = trainDat
sp_testDat  = testDat 
sp::coordinates(sp_trainDat) = ~x+y
sp::coordinates(sp_testDat) = ~x+y
crs(sp_trainDat) = crs(pred_stack_2019)
crs(sp_testDat) = crs(pred_stack_2019)


# superClass method &quot;mlc&quot; trainiert das Modell und klassifiziert im Anschluss
#raster::beginCluster(30)
prediction_mlc_2019   &lt;- superClass(pred_stack_2019, trainData = sp_trainDat[,1:16],valData = sp_testDat[,1:16], responseCol = &quot;class&quot;, model = &quot;mlc&quot;, tuneLength = 1, trainPartition = 0.3,verbose = TRUE)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |==================                                                    |  25%
  |                                                                            
  |===================================                                   |  50%
  |                                                                            
  |====================================================                  |  75%
  |                                                                            
  |======================================================================| 100%
## 
## Maximum Likelihood Classification 
## 
## 3485 samples
##   15 predictor
##    2 classes: &#39;clearcut&#39;, &#39;other&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 2787, 2789, 2788, 2788, 2788 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.9170739  0.4458375
## 
## [[1]]
##   TrainAccuracy TrainKappa method
## 1     0.9170739  0.4458375 custom
## 
## [[2]]
## Cross-Validated (5 fold) Confusion Matrix 
## 
## (entries are average cell counts across resamples)
##  
##           Reference
## Prediction clearcut other
##   clearcut     26.4  56.8
##   other         1.0 612.8
##                             
##  Accuracy (average) : 0.9171
## 
## 
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction clearcut other
##   clearcut     1503  2618
##   other          67 31177
##                                           
##                Accuracy : 0.9241          
##                  95% CI : (0.9213, 0.9268)
##     No Information Rate : 0.9556          
##     P-Value [Acc &gt; NIR] : 1               
##                                           
##                   Kappa : 0.4958          
##                                           
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.95732         
##             Specificity : 0.92253         
##          Pos Pred Value : 0.36472         
##          Neg Pred Value : 0.99786         
##              Prevalence : 0.04439         
##          Detection Rate : 0.04250         
##    Detection Prevalence : 0.11653         
##       Balanced Accuracy : 0.93993         
##                                           
##        &#39;Positive&#39; Class : clearcut        
## </code></pre>
<pre class="r"><code>prediction_mlc_2020       &lt;- superClass(pred_stack_2020, trainData = sp_trainDat[,1:16],valData = sp_testDat[,1:16], responseCol = &quot;class&quot;,model = &quot;mlc&quot;, tuneLength = 1, trainPartition = 0.3,verbose = TRUE)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |==================                                                    |  25%
  |                                                                            
  |===================================                                   |  50%
  |                                                                            
  |====================================================                  |  75%
  |                                                                            
  |======================================================================| 100%
## 
## Maximum Likelihood Classification 
## 
## 3485 samples
##   15 predictor
##    2 classes: &#39;clearcut&#39;, &#39;other&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 2788, 2788, 2788, 2789, 2787 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.9865103  0.8366808
## 
## [[1]]
##   TrainAccuracy TrainKappa method
## 1     0.9865103  0.8366808 custom
## 
## [[2]]
## Cross-Validated (5 fold) Confusion Matrix 
## 
## (entries are average cell counts across resamples)
##  
##           Reference
## Prediction clearcut other
##   clearcut     25.0   7.0
##   other         2.4 662.6
##                             
##  Accuracy (average) : 0.9865
## 
## 
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction clearcut other
##   clearcut     1436   422
##   other         134 33373
##                                           
##                Accuracy : 0.9843          
##                  95% CI : (0.9829, 0.9855)
##     No Information Rate : 0.9556          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.8296          
##                                           
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
##                                           
##             Sensitivity : 0.91465         
##             Specificity : 0.98751         
##          Pos Pred Value : 0.77287         
##          Neg Pred Value : 0.99600         
##              Prevalence : 0.04439         
##          Detection Rate : 0.04061         
##    Detection Prevalence : 0.05254         
##       Balanced Accuracy : 0.95108         
##                                           
##        &#39;Positive&#39; Class : clearcut        
## </code></pre>
<pre class="r"><code>saveRDS(prediction_mlc_2019, paste0(envrmt$path_data,&quot;prediction_mlc_2019.rds&quot;))
saveRDS(prediction_mlc_2020, paste0(envrmt$path_data,&quot;prediction_mlc_2020.rds&quot;))</code></pre>
</div>
<div id="random-forest" class="section level3">
<h3>Random forest</h3>
<p>Random Forests können sowohl für Regressions- als auch für Klassifizierungsaufgaben verwendet werden, wobei letztere besonders in der Umwelt-Fernerkundung relevant sind. Wie bei jeder maschinellen Lernmethode lernt auch das Random-Forest-Modell, Muster und Strukturen in den Daten selbst zu erkennen. Da auch der Random-Forest-Algorithmus Trainingsdaten benötigt, handelt es sich ebenfalls um eine überwachte Lernmethode.
<img src="images/Random_forest_diagram_complete.png" />!</p>
<p>Abbildung: Vereinfachte Darstellung der Klassifizierung von Daten durch Random Forest während des Trainings. Venkata Jagannath [CC BY-SA 4.0] via wikipedia.org</p>
<p>Ein Random-Forest-Algorithmus lernt über die Daten, indem zufällige Entscheidungsbäume erstellt werden - daher auch der Name. Für Klassifizierungsaufgaben nimmt der Algorithmus eine passende Instanz eines Entscheidungsbaumes aus dem Trainingsdatensatz und weist dem Pixel die korrespondierende Klasse zu. Dies wird mit allen verfügbaren Entscheidungsbäuumen wiederholt. Letzlichwird nach dem Winner-takes-it-all Prinzip das Pixel der Klasse zugeordnet, die die meisten Bäume aufweist.</p>
<pre class="r"><code># Einstellungen Modelltraining: cross-validation, 10 Wiederholungen
ctrlh = trainControl(method = &quot;cv&quot;,
                     number = 10,
                     savePredictions = TRUE)

#--- random forest model training
rf_model = train(trainDat[,2:16],      # in den Spalten 2 bis 16 stehen die Trainingsdaten (Prediktoren genannt)
                      trainDat[,1],         # in der Spalte 1 steht die zu klassizierende Variable (Response genannt)
                      method = &quot;rf&quot;,        # Methode hier rf für random forest
                      metric = &quot;Kappa&quot;,     # Qualitäts/Performanzmaß KAppa
                      trControl = ctrlh,    # obig erzeugte Trainingssteuerung soll eingelsen werden
                      importance = TRUE)    # Die Bedeung der Variablen wird mit abgespeichert

rf_model</code></pre>
<pre><code>## Random Forest 
## 
## 3493 samples
##   15 predictor
##    2 classes: &#39;clearcut&#39;, &#39;other&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 3144, 3144, 3144, 3143, 3144, 3144, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.9939869  0.9119655
##    8    0.9957053  0.9391842
##   15    0.9954187  0.9358398
## 
## Kappa was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 8.</code></pre>
<pre class="r"><code>#saveRDS(rf_model, paste0(envrmt$path_data,&quot;rf_model.rds&quot;))</code></pre>
</div>
<div id="schätzung-modellgüte" class="section level3">
<h3>Schätzung Modellgüte</h3>
<p>Die Testdaten werden nun für die unabhängige Qualitätsprüfung des Modells verwendet. Eine Wahrheits- oder Konfusionsmatrix zeigt an, wie präzise das Modell die korrekten Klassen vorhersagt. Die Hauptdiagonale der Matrix zeigt die Fälle an, in denen das Modell zutrifft. In unserer Klassifikation von nur 2 Klassen gilt allerdings der Sonderfall einer <a href="https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers">Beurteilung eines binären Klassifikators</a>.
Speziell für die hier verwendete Funktion finden sich ausführliche Erläuertungen in der <a href="https://topepo.github.io/caret/measuring-performance.html#measures-for-predicted-classes">caret Hilfe</a>.</p>
<p>Die wesentlichen Ausagen zur Modellgüte sind :</p>
<ul>
<li><em>‘Positive’ Class</em> = <strong>clearcut</strong>: wird mit der Sensitivität (<em>true positive rate</em>) erfasst, die die Wahrscheinlichkeit angibt, mit der ein positives Objekt korrekt als positiv klassifiziert wird.</li>
<li><em>‘Negative Class’</em> = <strong>other</strong>: wird mit der Spezifität (<em>true negative rate</em>) erfasst und gibt die Wahrscheinlichkeit an, mit der ein negatives Objekt korrekt als negativ klassifiziert wird</li>
<li><em>Positive and negative predictive values</em> geben für <em>clearcut</em> bzw. <em>other</em> die reale Perfomance an. Sie sind um die reale Häufigkeitsverteilung korrigiert und ein Schätzmass für die Präzision bzw. Performance des Modells bezüglich der jeweiligen Klassen.</li>
</ul>
<p>Trotz der hohen Werte sehen wir, dass die Klasse <em>clearcut</em> hier deutlich abfällt. Das kann durchaus als Hinweis auf die Notwendigkeit zur Verbesserung der Klassifikation aufgefasst werden.</p>
<p>Insgesamt kann das Modell jedoch als gut bezeichnet werden.</p>
<pre class="r"><code># ---- Berechnung der Konfusionsmatrix  ----
cm_rf &lt;- confusionMatrix(data = predict(rf_model, newdata = testDat), testDat$class)
cm_rf</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction clearcut other
##   clearcut     2442    42
##   other         153 63713
##                                           
##                Accuracy : 0.9971          
##                  95% CI : (0.9966, 0.9975)
##     No Information Rate : 0.9609          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9601          
##                                           
##  Mcnemar&#39;s Test P-Value : 3.346e-15       
##                                           
##             Sensitivity : 0.94104         
##             Specificity : 0.99934         
##          Pos Pred Value : 0.98309         
##          Neg Pred Value : 0.99760         
##              Prevalence : 0.03911         
##          Detection Rate : 0.03680         
##    Detection Prevalence : 0.03744         
##       Balanced Accuracy : 0.97019         
##                                           
##        &#39;Positive&#39; Class : clearcut        
## </code></pre>
</div>
<div id="vorhersage-auf-die-ausgangsdaten" class="section level3">
<h3>Vorhersage auf die Ausgangsdaten</h3>
<p>Nun sind wir soweit das überprüfte Modell auf unseren Datensatz anzuwenden. Üblicherweise wird das in der Fernerkundung Klassifikation genannt.</p>
<pre class="r"><code># Klassifikation (auch Vorhersage genannt)
prediction_rf_2019  = raster::predict(pred_stack_2019 ,rf_model)
prediction_rf_2020  = raster::predict(pred_stack_2020 ,rf_model)
saveRDS(prediction_rf_2019, paste0(envrmt$path_data,&quot;prediction_rf_2019.rds&quot;))
saveRDS(prediction_rf_2020, paste0(envrmt$path_data,&quot;prediction_rf_2020.rds&quot;))</code></pre>
<pre class="r"><code>prediction_rf_2019 = readRDS(paste0(envrmt$path_data,&quot;prediction_rf_2019.rds&quot;))
prediction_rf_2020 = readRDS(paste0(envrmt$path_data,&quot;prediction_rf_2020.rds&quot;))
prediction_mlc_2019 = readRDS(paste0(envrmt$path_data,&quot;prediction_mlc_2019.rds&quot;))
prediction_mlc_2020 = readRDS(paste0(envrmt$path_data,&quot;prediction_mlc_2020.rds&quot;))
## ---- Visualisierung mit mapview ----
mapview::mapshot(mapview::viewRGB(mask*pred_stack_2020, r = 4, g =3, b = 2,maxpixels =  1693870)+
  mapview(mask*prediction_rf_2019 , alpha.regions = 0.5, maxpixels =  1693870,
          col.regions = mapviewPalette(&quot;mapviewRasterColors&quot;),at = seq(0, nclasses, 1), legend = TRUE) +
  mapview(mask*prediction_rf_2020, alpha.regions = 0.5, maxpixels =  1693870,
          col.regions = mapviewPalette(&quot;mapviewRasterColors&quot;),at = seq(0, nclasses, 1), legend = FALSE) +
  mapview(mask*prediction_mlc_2019$map,alpha.regions = 0.5, maxpixels =  1693870,
          col.regions = mapviewPalette(&quot;mapviewRasterColors&quot;),at = seq(0, nclasses, 1), legend = FALSE) +
  mapview(mask*prediction_mlc_2020$map,alpha.regions = 0.5, maxpixels =  1693870,
          col.regions = mapviewPalette(&quot;mapviewRasterColors&quot;),at = seq(0, nclasses, 1), legend = FALSE),url = &quot;compare-class.html&quot;)</code></pre>
<pre><code>## Warning in raster::projectRaster(x, raster::projectExtent(x, crs =
## sp::CRS(epsg3857)), : input and ouput crs are the same</code></pre>
<iframe valign="center" src="compare-class.html" width="1024" height="960" frameborder="0" allowfullscreen="allowfullscreen">
</iframe>
<figcaption>
<em>Comparison of the two years and RF and MLC classification </em>
</figcaption>
<p>
<p>Bei einem visuellen Vergleich fällt auf, dass die <code>Random Forest</code> und <code>Maximumlikelihood</code> Klassifikationen Ergebnisse von vergleichbarer Güte liefern. Doch hält dieser Eindruck einer quantitativen Überprüfung Stand?</p>
</div>
</div>
<div id="weiterführende-unterstützung" class="section level2">
<h2>Weiterführende Unterstützung</h2>
<p>Betrachten Sie die nachfolgenden Ressourcen als Beispiele dafür, wie aus solchen, im Internet vielfältig verfügbaren Anleitungen, sich schrittweise eine bestimmte konzeptionelle und technische Vorgehensweise zur Bearbeitung einer Fragestellung <em>“herauskristallisiert”</em>. Nach viel Recherchearbeit und kritischer Gegenprüfung wird so ein aktuell innerhalb der wissenschaftlcihen Gemeinschaft als gesichert geltender <em>“Stand der Forschung”</em> identifiziert, der als zureichende Grundlage guter wissenschaftlicher Praxis betrachtet werden kann.</p>
<p>Arbeiten/Lesen Sie, auch zu Übungszwecken, die nachstehende Auswahl von Blogs und Hilfestellungen einmal durch.</p>
<ul>
<li>Robert J. Hijmans <a href="https://rspatial.org/raster/rs/5-supclassification.html">rspatial - supervised classification</a></li>
<li>Ivan Lizarazo <a href="https://rpubs.com/ials2un/rf_landcover">RPubs Tutorial</a></li>
<li>Sydney Goldstein <a href="https://urbanspatial.github.io/classifying_satellite_imagery_in_R/">blog</a></li>
<li>João Gonçalves <a href="https://www.r-exercises.com/2018/03/07/advanced-techniques-with-raster-data-part-2-supervised-classification/">supervised classification</a></li>
<li>Valentin Stefan <a href="https://valentinitnelav.github.io/satellite-image-classification-r/">pixel-based supervised classification</a></li>
</ul>
<p>Sie finden in den Beiträgen immer beides, technische Anleitungen und konzeptionelle oder konkrete fachliche Fragestellungen und Lösungswege. Sie ersetzen keineswegs die fachwissenschaftlichen Knntnisse. Aber Sie zeigen auf wie technisches und konzeptionelles Verständnis schrittweise erarbeiet werden kann und unterstützen, durch <em>“nachkochen”</em> und anwenden, die Kompetenzen eigenständig die Beantwortung von Fragestellungen anzugehen.</p>
<p>Ich möchte ausdrücklich Valentin Stefan den Autor des Blogbeitrags <a href="https://valentinitnelav.github.io/satellite-image-classification-r/">pixel-based supervised classification</a> zitieren:</p>
<div class="boxSuccess">
<p class="textline">
<em>“[…] Betrachten Sie diesen Inhalt als einen Blogbeitrag und nichts weiter. Er erhebt nicht den Anspruch, eine erschöpfende Übung oder ein Ersatz für Ihr kritisches Denken zu sein. […]”</em>
</div>
<div class="boxInfo">
<p class="textline">
Sie können alle notwendigen Skripte und Daten aus dem github repository <a href="https://github.com/gisma/geoinfo/archive/refs/heads/main.zip">laden</a>. Alternativ können sie das Repo auch als Projekt in Rstudio anlegen <a href="https://www.r-bloggers.com/2015/07/rstudio-and-github/">Rstudio github</a>.
´
</div>
</div>
</div>

                <style>
.button {
  border: none;
  border-radius: 4px 4px; 
  color: white;
  padding: 2px 4px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 12px;
  transition-duration: 0.5s;
  cursor: pointer;
  background-color: #4CAF50; 
  
}
.button1 a:link {
  color: #FFF;
  border-radius: 4px 4px;        
  background-color: #4CAF50; 
  
}

.button1 a:visited {
  color: white;
    border-radius: 4px 4px;        
  background-color: #4CAF50; 
  
}

.button1 a:hover {
  color: white;
    padding: 2px 4px;
    border-radius: 4px 4px;        
  background-color: #3FA043; 
  
}

.button1 a:active {
  color: white;
    border-radius: 4px 4px;        
  background-color: #4CAF50; 
  
}
}

.button1 {
  color: white;
  border-radius: 4px 4px;        
  background-color: #4CAF50; 
  
}


.button1:hover {
  background-color: #4CAF60;
    box-shadow:0 8px 16px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)
}

</style>


<div class="col-12 col-lg-10ish article-style">     
<p>Questions and mistakes but also suggestions and solutions are welcome.</p>
<script src="https://utteranc.es/client.js"
        repo="gisma-courses/gi-modules"
        issue-term="title"
        label="comments"
        theme="github-light"
        crossorigin="anonymous" 
        async>
</script>
<p>Due to an occasionally faulty page redirection, a 404 error may occur. please use the alternative <button class="button button1"> <a href="https://api.utteranc.es/authorize?redirect_uri=https%3a%2f%2fgisma-courses.github.io%2fgi-modules%2fpost%2f2021-12-16-change-detection%2f">Sign in with GitHub</a></button></p>
    
</div>

                
                
                <hr>
               
            </div>

            
            
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">Content</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
            
            
            

            
            <div class="
                col-lg-2 col-lg-offset-0
                col-md-3 col-md-offset-1
                sidebar-container
                catalog-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">Tag Nav</a></h5>
                    <div class="tags">
                        
                        
                        
                        <a href="/gi-modules/tags/agis" title="agis">
                            agis
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/change-detection" title="change-detection">
                            change-detection
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/ecology" title="ecology">
                            ecology
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/forest" title="forest">
                            forest
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/lidar" title="lidar">
                            lidar
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/project-management" title="project-management">
                            project-management
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/remote-sensing" title="remote-sensing">
                            remote-sensing
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/reproducibility" title="reproducibility">
                            reproducibility
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/resources" title="resources">
                            resources
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/rmarkdown" title="rmarkdown">
                            rmarkdown
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/scripts" title="scripts">
                            scripts
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/validation" title="validation">
                            validation
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/working-environment" title="working-environment">
                            working-environment
                        </a>
                        
                        
                        
                        <a href="/gi-modules/tags/xtra" title="xtra">
                            xtra
                        </a>
                        
                        
                    </div>
                </section>
                 

                
                
                      
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                   
                    

                    
                    
                    

                    

		    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
            
            
            
                </ul>
		<p class="copyright text-muted">
                    Copyright &copy; gi-modules 2022
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> 
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function loadAsync(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

  
  <script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>




<script>
    
    if($('#tag_cloud').length !== 0){
        loadAsync("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    loadAsync("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>









<script type="text/javascript">
    function generateCatalog(selector) {

        
        
        
        
            _containerSelector = 'div.post-container'
        

        
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        
        $(selector).html('')

        
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    


    loadAsync("\/gi-modules\/js\/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
    
</script>
<script src="js/toggle.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js" integrity="sha512-yUUc0qWm2rhM7X0EFe82LNnv2moqArj5nro/w1bi05A09hRVeIZbN6jlMoyu0+4I/Bu4Ck/85JQIU82T82M28w==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/languages/r.min.js" integrity="sha512-EArMU8fPxOr7xC5sNepok4l7Yhahn3NRFSeWH+/zOhbiZVCnY2mLQtC/lUU/Q6+zMH6K22l0tur8D/jTii3ZUw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>

<script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script>
$(document).ready(function() {

  $chunks = $('.fold');

  $chunks.each(function () {

    
    if ( $(this).hasClass('s') ) {
      $('pre.r', this).prepend("<div class=\"showopt\">Show Source</div>");
      $('pre.r', this).children('code').attr('class', 'folded');
    }

    
    if ( $(this).hasClass('o') ) {
      $('pre:not(.r)', this).has('code').prepend("<div class=\"showopt\">Show Output</div>");
      $('pre:not(.r)', this).children('code:not(r)').addClass('folded');

      
      $(this).find('img').wrap('<pre class=\"plot\"></pre>');
      $('pre.plot', this).prepend("<div class=\"showopt\">Show Plot</div>");
      $('pre.plot', this).children('img').addClass('folded');

    }
  });

  
  $('.folded').css('display', 'none')

  
  $('.showopt').click(function() {
    var label = $(this).html();
    if (label.indexOf("Show") >= 0) {
      $(this).html(label.replace("Show", "Hide"));
    } else {
      $(this).html(label.replace("Hide", "Show"));
    }
    $(this).siblings('code, img').slideToggle('fast', 'swing');
  });
});
</script>

<style>
.showopt {
  class: btn btn-primary;
  padding-bottom: 2px;
  background-color: #004c93;
  color: #FFFFFF; 
  width: 80px;
  height: 14px;
  font-size:80%;
  text-align: center;
  vertical-align: middle !important;
    font-family: sans-serif;
  border-radius: 2px;
}

.showopt:hover {
    background-color: green;
    color: #FFD400;
}

pre.plot {
  background-color: white !important;
}

.figcaption {
  padding-right: 50px;
  padding-left: 50px;
  font-family: Tahoma, Verdana, sans-serif;
  font-style: italic;
  bottom: 0;
  text-align: justify;
  font-size: 13px;
  border: 0px solid blue;
}
</style>



<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/idea.min.css' rel='stylesheet' type='text/css' />





</body>
</html>
